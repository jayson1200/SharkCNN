{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import psutil\n",
    "import pynvml\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "sys.path.append('/home/meribejayson/Desktop/Projects/SharkCNN/training_models/dataloaders/')\n",
    "\n",
    "from train_dataset import SharkDatasetTrain as SharkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Couldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "megaset_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/\"\n",
    "megaset_train_images_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/images/\"\n",
    "megaset_train_labels_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/labels/\"\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_layer_num = int(input_size / 2)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_layer_num)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_layer_num + input_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = torch.cat((x, h), dim=1)\n",
    "        h = self.linear2(h)\n",
    "        \n",
    "        return self.sig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_dataset = SharkDataset()\n",
    "data_loader = data.DataLoader(shark_dataset, batch_size=500_000, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(\"./train-final-2/lr_weights_train_2.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(85)\n",
    "# model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_NUM = 2e120\n",
    "target_loss_change = 1e-6\n",
    "exps_in_iter = (image_height * image_width * 2)\n",
    "kappa = 1 / 323\n",
    "kappa_inv = 323\n",
    "coef = (1 + kappa) / 2\n",
    "small_peturb = 2e-120\n",
    "\n",
    "def train_model(model, optimizer, data_loader):\n",
    "    model.train()\n",
    "    last_average_loss = LARGE_NUM\n",
    "    curr_average_loss = 0\n",
    "    curr_iter = 1\n",
    "\n",
    "    while(np.abs(curr_average_loss - last_average_loss) > target_loss_change):\n",
    "        \n",
    "        total_iter_avg_loss = 0\n",
    "\n",
    "        for point in data_loader:\n",
    "            data_inputs = point[:, :-1].to(device).float()\n",
    "            data_labels = point[:, -1].to(device).float()\n",
    "\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "\n",
    "            weights = torch.clone(data_labels)\n",
    "            weights[data_labels == 0.0] = 1\n",
    "            weights[data_labels == 1.0] = kappa_inv\n",
    "\n",
    "            weights = coef * weights\n",
    "            \n",
    "            data_labels[data_labels == 0.0] = data_labels[data_labels == 0.0] + small_peturb\n",
    "            data_labels[data_labels == 1.0] = data_labels[data_labels == 1.0] - small_peturb\n",
    "            \n",
    "            loss_module = nn.BCELoss(weight=weights)\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_iter_avg_loss += loss.item()\n",
    " \n",
    "        last_average_loss = curr_average_loss\n",
    "        curr_average_loss = total_iter_avg_loss\n",
    "        \n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        clear_output(wait=True)\n",
    "        print(f'Current iteration: {curr_iter - 1}, Average Loss: {last_average_loss}')\n",
    "        print(f'Current iteration: {curr_iter}, Average Loss: {curr_average_loss}')\n",
    "        print(f\"CPU Usage: {psutil.cpu_percent()}% GPU memory usage: {int(info.used / info.total)}% \\n\")\n",
    "\n",
    "        print(\"Current Parameters:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "\n",
    "        curr_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 19\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, data_loader)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(np\u001b[38;5;241m.\u001b[39mabs(curr_average_loss \u001b[38;5;241m-\u001b[39m last_average_loss) \u001b[38;5;241m>\u001b[39m target_loss_change):\n\u001b[1;32m     17\u001b[0m     total_iter_avg_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m point \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     20\u001b[0m         data_inputs \u001b[38;5;241m=\u001b[39m point[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     21\u001b[0m         data_labels \u001b[38;5;241m=\u001b[39m point[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/cs229proj/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[-0.0295, -0.0084, -0.0275,  ..., -0.0002, -0.0007, -0.0008],\n",
      "        [-0.0022,  0.0188, -0.0003,  ..., -0.0003, -0.0006, -0.0007],\n",
      "        [ 0.0197,  0.0840,  0.0184,  ..., -0.0152, -0.0154, -0.0177],\n",
      "        ...,\n",
      "        [-0.0496, -0.0077, -0.0382,  ..., -0.0153, -0.0165, -0.0190],\n",
      "        [-0.0030,  0.0174, -0.0007,  ..., -0.0004, -0.0005, -0.0008],\n",
      "        [ 0.0251,  0.0683,  0.0280,  ..., -0.0267, -0.0178, -0.0266]],\n",
      "       device='cuda:0')), ('linear1.bias', tensor([ 0.4571,  0.4926,  0.3845,  0.8409,  0.4540,  0.3664,  0.3033,  0.4902,\n",
      "         0.4560,  0.2078,  0.3590,  0.3504,  0.3298,  0.4441,  1.0028, -0.0083,\n",
      "        -0.0158,  0.2924,  0.3626, -0.0121,  0.7857,  0.0215,  0.3392,  0.7735,\n",
      "         0.3349,  0.3200,  0.9406,  0.3883,  0.3078,  0.0150, -0.0304,  0.6940,\n",
      "         0.3596,  0.7300,  0.4204,  0.6676,  0.3773,  0.3340,  0.5896,  0.4075,\n",
      "         0.5844,  0.3671], device='cuda:0')), ('linear2.weight', tensor([[ 1.1929e-01, -1.5405e-01,  9.9273e-02, -1.0147e-02,  1.2473e-01,\n",
      "          3.9963e-02,  6.7682e-02,  1.7156e-02,  1.1556e-01,  3.7195e-02,\n",
      "          2.4300e-02,  1.4089e-02,  1.7376e-02, -6.7850e-02, -1.6453e-02,\n",
      "         -4.5828e-02, -8.7898e-02, -2.4508e-02, -1.0501e-01, -5.8769e-02,\n",
      "         -5.4711e-02, -7.7907e-02, -9.1885e-02, -1.5525e-02, -2.4126e-02,\n",
      "          1.7590e-02, -1.0417e-01, -8.6538e-02, -3.0112e-02, -4.8178e-02,\n",
      "         -6.5809e-02, -6.4851e-02,  1.3587e-02, -1.8791e-02, -1.5414e-02,\n",
      "         -1.2046e-02, -3.5164e-02, -4.1831e-03,  1.1215e-02,  9.2816e-03,\n",
      "          3.0638e-02,  5.1083e-03,  4.2157e-03,  2.5237e-03,  1.1384e-02,\n",
      "          1.6704e-02,  5.9859e-03, -2.4938e-03,  1.5601e-02, -2.6173e-03,\n",
      "          9.3004e-03,  1.0149e-02,  3.4711e-03,  3.3145e-03,  1.4610e-03,\n",
      "         -1.5668e-03,  2.0986e-02, -4.0341e-04, -8.2122e-03,  2.5085e-03,\n",
      "          4.2265e-03,  3.3328e-02, -5.1156e-02,  3.4621e-02,  4.1036e-02,\n",
      "          2.7340e-02, -1.8506e-02,  3.9674e-02,  6.8759e-03,  6.0261e-03,\n",
      "          1.1442e-02, -3.0612e-03, -7.9699e-03, -2.2846e-02,  3.9492e-02,\n",
      "          2.9287e-02, -4.4842e-02, -2.1891e-02,  3.7183e-02,  3.6839e-03,\n",
      "          3.0644e-02, -7.1797e-03, -4.4779e-02, -1.7450e-04, -1.0599e-02,\n",
      "         -3.3114e-01, -3.1061e-01, -3.1650e-01, -6.1637e-01, -3.5338e-01,\n",
      "         -3.7211e-01, -3.7607e-01, -3.0996e-01, -3.3153e-01, -1.5989e-01,\n",
      "         -3.1135e-01, -3.3595e-01, -3.3942e-01, -2.9471e-01, -7.3696e-01,\n",
      "          2.6686e-03,  1.5534e-02, -3.4786e-01, -3.5592e-01,  1.4702e-02,\n",
      "         -5.9496e-01, -1.1239e-02, -3.1458e-01, -5.4897e-01, -3.0559e-01,\n",
      "         -3.5431e-01, -6.8400e-01, -3.1761e-01, -3.4458e-01, -1.0625e-02,\n",
      "          2.3952e-02, -4.8807e-01, -3.6775e-01, -5.0352e-01, -3.0888e-01,\n",
      "         -4.8544e-01, -2.8591e-01, -3.7578e-01, -3.8567e-01, -3.3789e-01,\n",
      "         -3.9637e-01, -3.2396e-01]], device='cuda:0')), ('linear2.bias', tensor([-0.1730], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "pynvml.nvmlShutdown()\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "torch.save(state_dict, \"ann_weights_train_1.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
