{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpynvml\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloaders\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msharkdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SharkDataset\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "\n",
    "from ..dataloaders.sharkdataset import SharkDatasetTrain as SharkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Couldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "megaset_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/\"\n",
    "megaset_train_images_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/images/\"\n",
    "megaset_train_labels_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/labels/\"\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_layer_num = int(input_size / 2)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_layer_num)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_layer_num + input_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = torch.cat((x, h), dim=1)\n",
    "        h = self.linear2(h)\n",
    "        \n",
    "        return self.sig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_dataset = SharkDataset()\n",
    "data_loader = data.DataLoader(shark_dataset, batch_size=500_000, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(\"./train-final-2/lr_weights_train_2.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(85)\n",
    "# model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_NUM = 2e120\n",
    "target_loss_change = 1e-6\n",
    "exps_in_iter = (image_height * image_width * 2)\n",
    "kappa = 1 / 323\n",
    "kappa_inv = 323\n",
    "coef = (1 + kappa) / 2\n",
    "small_peturb = 2e-120\n",
    "\n",
    "def train_model(model, optimizer, data_loader):\n",
    "    model.train()\n",
    "    last_average_loss = LARGE_NUM\n",
    "    curr_average_loss = 0\n",
    "    curr_iter = 1\n",
    "\n",
    "    while(np.abs(curr_average_loss - last_average_loss) > target_loss_change):\n",
    "        \n",
    "        total_iter_avg_loss = 0\n",
    "\n",
    "        for point in data_loader:\n",
    "            data_inputs = point[:, :-1].to(device).float()\n",
    "            data_labels = point[:, -1].to(device).float()\n",
    "\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "\n",
    "            weights = torch.clone(data_labels)\n",
    "            weights[data_labels == 0.0] = 1\n",
    "            weights[data_labels == 1.0] = kappa_inv\n",
    "\n",
    "            weights = coef * weights\n",
    "            \n",
    "            data_labels[data_labels == 0.0] = data_labels[data_labels == 0.0] + small_peturb\n",
    "            data_labels[data_labels == 1.0] = data_labels[data_labels == 1.0] - small_peturb\n",
    "            \n",
    "            loss_module = nn.BCELoss(weight=weights)\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_iter_avg_loss += loss.item()\n",
    " \n",
    "        last_average_loss = curr_average_loss\n",
    "        curr_average_loss = total_iter_avg_loss\n",
    "        \n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        clear_output(wait=True)\n",
    "        print(f'Current iteration: {curr_iter - 1}, Average Loss: {last_average_loss}')\n",
    "        print(f'Current iteration: {curr_iter}, Average Loss: {curr_average_loss}')\n",
    "        print(f\"CPU Usage: {psutil.cpu_percent()}% GPU memory usage: {int(info.used / info.total)}% \\n\")\n",
    "\n",
    "        print(\"Current Parameters:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "\n",
    "        curr_iter += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration: 92, Average Loss: 0.006014670929289423\n",
      "Current iteration: 93, Average Loss: 0.006014301354298368\n",
      "CPU Usage: 17.1% GPU memory usage: 0% \n",
      "\n",
      "Current Parameters:\n",
      "linear1.weight tensor([[-0.0295, -0.0084, -0.0275,  ..., -0.0002, -0.0007, -0.0008],\n",
      "        [-0.0022,  0.0188, -0.0003,  ..., -0.0003, -0.0006, -0.0007],\n",
      "        [ 0.0197,  0.0840,  0.0184,  ..., -0.0152, -0.0154, -0.0177],\n",
      "        ...,\n",
      "        [-0.0496, -0.0077, -0.0382,  ..., -0.0153, -0.0165, -0.0190],\n",
      "        [-0.0030,  0.0174, -0.0007,  ..., -0.0004, -0.0005, -0.0008],\n",
      "        [ 0.0251,  0.0683,  0.0280,  ..., -0.0267, -0.0178, -0.0266]],\n",
      "       device='cuda:0')\n",
      "linear1.bias tensor([ 0.4571,  0.4926,  0.3845,  0.8409,  0.4540,  0.3664,  0.3033,  0.4902,\n",
      "         0.4560,  0.2078,  0.3590,  0.3504,  0.3298,  0.4441,  1.0028, -0.0083,\n",
      "        -0.0158,  0.2924,  0.3626, -0.0121,  0.7857,  0.0215,  0.3392,  0.7735,\n",
      "         0.3349,  0.3200,  0.9406,  0.3883,  0.3078,  0.0150, -0.0304,  0.6940,\n",
      "         0.3596,  0.7300,  0.4204,  0.6676,  0.3773,  0.3340,  0.5896,  0.4075,\n",
      "         0.5844,  0.3671], device='cuda:0')\n",
      "linear2.weight tensor([[ 1.1929e-01, -1.5405e-01,  9.9273e-02, -1.0147e-02,  1.2473e-01,\n",
      "          3.9963e-02,  6.7682e-02,  1.7156e-02,  1.1556e-01,  3.7195e-02,\n",
      "          2.4300e-02,  1.4089e-02,  1.7376e-02, -6.7850e-02, -1.6453e-02,\n",
      "         -4.5828e-02, -8.7898e-02, -2.4508e-02, -1.0501e-01, -5.8769e-02,\n",
      "         -5.4711e-02, -7.7907e-02, -9.1885e-02, -1.5525e-02, -2.4126e-02,\n",
      "          1.7590e-02, -1.0417e-01, -8.6538e-02, -3.0112e-02, -4.8178e-02,\n",
      "         -6.5809e-02, -6.4851e-02,  1.3587e-02, -1.8791e-02, -1.5414e-02,\n",
      "         -1.2046e-02, -3.5164e-02, -4.1831e-03,  1.1215e-02,  9.2816e-03,\n",
      "          3.0638e-02,  5.1083e-03,  4.2157e-03,  2.5237e-03,  1.1384e-02,\n",
      "          1.6704e-02,  5.9859e-03, -2.4938e-03,  1.5601e-02, -2.6173e-03,\n",
      "          9.3004e-03,  1.0149e-02,  3.4711e-03,  3.3145e-03,  1.4610e-03,\n",
      "         -1.5668e-03,  2.0986e-02, -4.0341e-04, -8.2122e-03,  2.5085e-03,\n",
      "          4.2265e-03,  3.3328e-02, -5.1156e-02,  3.4621e-02,  4.1036e-02,\n",
      "          2.7340e-02, -1.8506e-02,  3.9674e-02,  6.8759e-03,  6.0261e-03,\n",
      "          1.1442e-02, -3.0612e-03, -7.9699e-03, -2.2846e-02,  3.9492e-02,\n",
      "          2.9287e-02, -4.4842e-02, -2.1891e-02,  3.7183e-02,  3.6839e-03,\n",
      "          3.0644e-02, -7.1797e-03, -4.4779e-02, -1.7450e-04, -1.0599e-02,\n",
      "         -3.3114e-01, -3.1061e-01, -3.1650e-01, -6.1637e-01, -3.5338e-01,\n",
      "         -3.7211e-01, -3.7607e-01, -3.0996e-01, -3.3153e-01, -1.5989e-01,\n",
      "         -3.1135e-01, -3.3595e-01, -3.3942e-01, -2.9471e-01, -7.3696e-01,\n",
      "          2.6686e-03,  1.5534e-02, -3.4786e-01, -3.5592e-01,  1.4702e-02,\n",
      "         -5.9496e-01, -1.1239e-02, -3.1458e-01, -5.4897e-01, -3.0559e-01,\n",
      "         -3.5431e-01, -6.8400e-01, -3.1761e-01, -3.4458e-01, -1.0625e-02,\n",
      "          2.3952e-02, -4.8807e-01, -3.6775e-01, -5.0352e-01, -3.0888e-01,\n",
      "         -4.8544e-01, -2.8591e-01, -3.7578e-01, -3.8567e-01, -3.3789e-01,\n",
      "         -3.9637e-01, -3.2396e-01]], device='cuda:0')\n",
      "linear2.bias tensor([-0.1730], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "train_model(model, optimizer, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear1.weight', tensor([[-0.0295, -0.0084, -0.0275,  ..., -0.0002, -0.0007, -0.0008],\n",
      "        [-0.0022,  0.0188, -0.0003,  ..., -0.0003, -0.0006, -0.0007],\n",
      "        [ 0.0197,  0.0840,  0.0184,  ..., -0.0152, -0.0154, -0.0177],\n",
      "        ...,\n",
      "        [-0.0496, -0.0077, -0.0382,  ..., -0.0153, -0.0165, -0.0190],\n",
      "        [-0.0030,  0.0174, -0.0007,  ..., -0.0004, -0.0005, -0.0008],\n",
      "        [ 0.0251,  0.0683,  0.0280,  ..., -0.0267, -0.0178, -0.0266]],\n",
      "       device='cuda:0')), ('linear1.bias', tensor([ 0.4571,  0.4926,  0.3845,  0.8409,  0.4540,  0.3664,  0.3033,  0.4902,\n",
      "         0.4560,  0.2078,  0.3590,  0.3504,  0.3298,  0.4441,  1.0028, -0.0083,\n",
      "        -0.0158,  0.2924,  0.3626, -0.0121,  0.7857,  0.0215,  0.3392,  0.7735,\n",
      "         0.3349,  0.3200,  0.9406,  0.3883,  0.3078,  0.0150, -0.0304,  0.6940,\n",
      "         0.3596,  0.7300,  0.4204,  0.6676,  0.3773,  0.3340,  0.5896,  0.4075,\n",
      "         0.5844,  0.3671], device='cuda:0')), ('linear2.weight', tensor([[ 1.1929e-01, -1.5405e-01,  9.9273e-02, -1.0147e-02,  1.2473e-01,\n",
      "          3.9963e-02,  6.7682e-02,  1.7156e-02,  1.1556e-01,  3.7195e-02,\n",
      "          2.4300e-02,  1.4089e-02,  1.7376e-02, -6.7850e-02, -1.6453e-02,\n",
      "         -4.5828e-02, -8.7898e-02, -2.4508e-02, -1.0501e-01, -5.8769e-02,\n",
      "         -5.4711e-02, -7.7907e-02, -9.1885e-02, -1.5525e-02, -2.4126e-02,\n",
      "          1.7590e-02, -1.0417e-01, -8.6538e-02, -3.0112e-02, -4.8178e-02,\n",
      "         -6.5809e-02, -6.4851e-02,  1.3587e-02, -1.8791e-02, -1.5414e-02,\n",
      "         -1.2046e-02, -3.5164e-02, -4.1831e-03,  1.1215e-02,  9.2816e-03,\n",
      "          3.0638e-02,  5.1083e-03,  4.2157e-03,  2.5237e-03,  1.1384e-02,\n",
      "          1.6704e-02,  5.9859e-03, -2.4938e-03,  1.5601e-02, -2.6173e-03,\n",
      "          9.3004e-03,  1.0149e-02,  3.4711e-03,  3.3145e-03,  1.4610e-03,\n",
      "         -1.5668e-03,  2.0986e-02, -4.0341e-04, -8.2122e-03,  2.5085e-03,\n",
      "          4.2265e-03,  3.3328e-02, -5.1156e-02,  3.4621e-02,  4.1036e-02,\n",
      "          2.7340e-02, -1.8506e-02,  3.9674e-02,  6.8759e-03,  6.0261e-03,\n",
      "          1.1442e-02, -3.0612e-03, -7.9699e-03, -2.2846e-02,  3.9492e-02,\n",
      "          2.9287e-02, -4.4842e-02, -2.1891e-02,  3.7183e-02,  3.6839e-03,\n",
      "          3.0644e-02, -7.1797e-03, -4.4779e-02, -1.7450e-04, -1.0599e-02,\n",
      "         -3.3114e-01, -3.1061e-01, -3.1650e-01, -6.1637e-01, -3.5338e-01,\n",
      "         -3.7211e-01, -3.7607e-01, -3.0996e-01, -3.3153e-01, -1.5989e-01,\n",
      "         -3.1135e-01, -3.3595e-01, -3.3942e-01, -2.9471e-01, -7.3696e-01,\n",
      "          2.6686e-03,  1.5534e-02, -3.4786e-01, -3.5592e-01,  1.4702e-02,\n",
      "         -5.9496e-01, -1.1239e-02, -3.1458e-01, -5.4897e-01, -3.0559e-01,\n",
      "         -3.5431e-01, -6.8400e-01, -3.1761e-01, -3.4458e-01, -1.0625e-02,\n",
      "          2.3952e-02, -4.8807e-01, -3.6775e-01, -5.0352e-01, -3.0888e-01,\n",
      "         -4.8544e-01, -2.8591e-01, -3.7578e-01, -3.8567e-01, -3.3789e-01,\n",
      "         -3.9637e-01, -3.2396e-01]], device='cuda:0')), ('linear2.bias', tensor([-0.1730], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "pynvml.nvmlShutdown()\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "torch.save(state_dict, \"ann_weights_train_1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "\n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "\n",
    "            # Determine prediction of model on dev set\n",
    "            data_inputs, data_labels = data_inputs.to(device), data_labels.to(device)\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "\n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "\n",
    "    acc = true_preds / num_preds\n",
    "    print(f\"Accuracy of the model: {100.0*acc:4.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
