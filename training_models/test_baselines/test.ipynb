{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append('/home/meribejayson/Desktop/Projects/SharkCNN/training_models/dataloaders/')\n",
    "\n",
    "from test_dataset import SharkDatasetTest as SharkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/LOGISTIC-REG/train-final-3/lr_weights_train_3.tar\"\n",
    "ann_model_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/ANN/train-1/ann_weights_train_1.tar\"\n",
    "\n",
    "state_dict_lr = torch.load(lr_model_path)\n",
    "state_dict_ann = torch.load(ann_model_path)\n",
    "\n",
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Couldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_layer_num = int(input_size / 2)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_layer_num)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_layer_num + input_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = torch.cat((x, h), dim=1)\n",
    "        h = self.linear2(h)\n",
    "        \n",
    "        return self.sig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegresion(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return self.sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SharkDataset()\n",
    "\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=500_000, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegresion(\n",
       "  (linear): Linear(in_features=85, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_state = torch.load(\"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/ANN/train-1/ann_weights_train_1.tar\")\n",
    "lr_state = torch.load(\"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/LOGISTIC-REG/train-final-3/lr_weights_train_3.tar\")\n",
    "\n",
    "ann_model = ANN(85)\n",
    "ann_model.load_state_dict(ann_state)\n",
    "ann_model.to(device)\n",
    "\n",
    "\n",
    "lr_model = LogisticRegresion(85)\n",
    "lr_model.load_state_dict(lr_state)\n",
    "lr_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, data_labels):\n",
    "    conf_thresholds = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] \n",
    "    precision_varying = []\n",
    "    recall_varying = []\n",
    "    f1_score_varying = []\n",
    "\n",
    "    print(preds)\n",
    "    print(preds.size())\n",
    "    for thresh in conf_thresholds:\n",
    "        TP = preds[(preds > thresh) & (data_labels == 1.0)].size(dim=0)\n",
    "        FP = preds[(preds > thresh) & (data_labels == 0.0)].size(dim=0)\n",
    "        FN = preds[(preds < thresh) & (data_labels == 1.0)].size(dim=0)\n",
    "\n",
    "        curr_thresh_precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        curr_thresh_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "        curr_thresh_f1_score = (2 * curr_thresh_precision * curr_thresh_recall) / (curr_thresh_recall + curr_thresh_precision) \n",
    "\n",
    "        precision_varying.append(curr_thresh_precision)\n",
    "        recall_varying.append(curr_thresh_recall)\n",
    "        f1_score_varying.append(curr_thresh_f1_score)\n",
    "\n",
    "    MAP_50 = precision_varying[0]\n",
    "    MAP50_95 = np.mean(np.array(precision_varying))\n",
    "\n",
    "    best_f1_score_idx = np.argmax(np.array(curr_thresh_f1_score))\n",
    "    \n",
    "    f1_score = f1_score_varying[best_f1_score_idx]\n",
    "    recall = recall_varying[best_f1_score_idx]\n",
    "    precision = precision_varying[best_f1_score_idx]\n",
    "\n",
    "    return {\n",
    "        \"MAP50\": MAP_50,\n",
    "        \"MAP50_95\": MAP50_95,\n",
    "        \"F1_Score\": f1_score,\n",
    "        \"Recall\": recall,\n",
    "        \"Precision\": precision\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader):\n",
    "    ann_model.eval()\n",
    "    lr_model.eval()\n",
    "\n",
    "    map50_ann = []\n",
    "    map50_95_ann = []\n",
    "    f1_score_ann = []\n",
    "    recall_ann = []\n",
    "    precision_ann = []\n",
    "\n",
    "    map50_lr = []\n",
    "    map50_95_lr = []\n",
    "    f1_score_lr = []\n",
    "    recall_lr = []\n",
    "    precision_lr = []\n",
    "\n",
    "    curr_iter = 1\n",
    "\n",
    "    while(True):\n",
    "        with torch.no_grad():\n",
    "            for point in data_loader:\n",
    "                data_inputs = point[:, :-1].to(device).float()\n",
    "                data_labels = point[:, -1].to(device).float()\n",
    "\n",
    "                ann_preds = ann_model(data_inputs)\n",
    "                ann_preds = ann_preds.squeeze(dim=1)\n",
    "\n",
    "                lr_preds = lr_model(data_inputs)\n",
    "                lr_preds = lr_preds.squeeze(dim=1)\n",
    "\n",
    "            metrics_ann_dict = calculate_metrics(ann_preds, data_labels)\n",
    "            metrics_lr_dict = calculate_metrics(lr_preds, data_labels)\n",
    "\n",
    "            map50_ann.append(metrics_ann_dict[\"MAP50\"])\n",
    "            map50_95_ann.append(metrics_ann_dict[\"MAP50_95\"])\n",
    "            f1_score_ann.append(metrics_ann_dict[\"F1_Score\"])\n",
    "            recall_ann.append(metrics_ann_dict[\"Recall\"])\n",
    "            precision_ann.append(metrics_ann_dict[\"Precision\"])\n",
    "\n",
    "            map50_lr.append(metrics_lr_dict[\"MAP50\"])\n",
    "            map50_95_lr.append(metrics_lr_dict[\"MAP50_95\"])\n",
    "            f1_score_lr.append(metrics_lr_dict[\"F1_Score\"])\n",
    "            recall_lr.append(metrics_lr_dict[\"Recall\"])\n",
    "            precision_lr.append(metrics_lr_dict[\"Precision\"])\n",
    "\n",
    "            MAP_50_ANN = np.mean(np.array(map50_ann))\n",
    "            MAP_50_95_ANN = np.mean(np.array(map50_95_ann))\n",
    "            f1_score_ANN = np.mean(np.array(f1_score_ann))\n",
    "            recall_ANN = np.mean(np.array(recall_ann))\n",
    "            precision_ANN = np.mean(np.array(precision_ann))\n",
    "\n",
    "            MAP_50_LR = np.mean(np.array(map50_lr))\n",
    "            MAP_50_95_LR = np.mean(np.array(map50_95_lr))\n",
    "            f1_score_LR = np.mean(np.array(f1_score_lr))\n",
    "            recall_LR = np.mean(np.array(recall_lr))\n",
    "            precision_LR = np.mean(np.array(precision_lr))\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "            print(f'Current iteration: {curr_iter}')\n",
    "            print(f'================================================')\n",
    "            print(\"ANN Metrics\")\n",
    "            print(f\"MAP50: {MAP_50_ANN} MAP50-95: {MAP_50_95_ANN} Precision: {precision_ANN} Recall: {recall_ANN} F1 score: {f1_score_ANN}\")\n",
    "            print(\"\\n\")\n",
    "            print(\"LR Metrics\")\n",
    "            print(f\"MAP50: {MAP_50_LR} MAP50-95: {MAP_50_95_LR} Precision: {precision_LR} Recall: {recall_LR} F1 score: {f1_score_LR}\")\n",
    "            print(\"==================================================\")\n",
    "            print(f\"CPU Usage: {psutil.cpu_percent()}% GPU memory usage: {int(info.used / info.total)}% \\n\")\n",
    "\n",
    "        curr_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fabc9a82790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fabc9a82790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fabc9a82790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fabc9a82790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fabc9a82790>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1462, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/meribejayson/anaconda3/envs/cs229proj/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0004, 0.0004, 0.0001,  ..., 0.0004, 0.0003, 0.0003], device='cuda:0')\n",
      "<built-in method size of Tensor object at 0x7fab24788a90>\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[53], line 31\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(data_loader)\u001b[0m\n\u001b[1;32m     28\u001b[0m     lr_preds \u001b[38;5;241m=\u001b[39m lr_model(data_inputs)\n\u001b[1;32m     29\u001b[0m     lr_preds \u001b[38;5;241m=\u001b[39m lr_preds\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m metrics_ann_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m metrics_lr_dict \u001b[38;5;241m=\u001b[39m calculate_metrics(lr_preds, data_labels)\n\u001b[1;32m     34\u001b[0m map50_ann\u001b[38;5;241m.\u001b[39mappend(metrics_ann_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAP50\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[0;32mIn[52], line 14\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(preds, data_labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m FP \u001b[38;5;241m=\u001b[39m preds[(preds \u001b[38;5;241m>\u001b[39m thresh) \u001b[38;5;241m&\u001b[39m (data_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m)]\u001b[38;5;241m.\u001b[39msize(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     12\u001b[0m FN \u001b[38;5;241m=\u001b[39m preds[(preds \u001b[38;5;241m<\u001b[39m thresh) \u001b[38;5;241m&\u001b[39m (data_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1.0\u001b[39m)]\u001b[38;5;241m.\u001b[39msize(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m curr_thresh_precision \u001b[38;5;241m=\u001b[39m \u001b[43mTP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTP\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mFP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m curr_thresh_recall \u001b[38;5;241m=\u001b[39m TP \u001b[38;5;241m/\u001b[39m (TP \u001b[38;5;241m+\u001b[39m FN)\n\u001b[1;32m     16\u001b[0m curr_thresh_f1_score \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m curr_thresh_precision \u001b[38;5;241m*\u001b[39m curr_thresh_recall) \u001b[38;5;241m/\u001b[39m (curr_thresh_recall \u001b[38;5;241m+\u001b[39m curr_thresh_precision) \n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "eval_model(test_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
