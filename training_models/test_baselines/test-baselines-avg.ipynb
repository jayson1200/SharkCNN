{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "\n",
    "sys.path.append('/home/meribejayson/Desktop/Projects/SharkCNN/training_models/dataloaders/')\n",
    "\n",
    "from test_dataset import SharkDatasetTest as SharkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/LOGISTIC-REG/train-final-3/lr_weights_train_3.tar\"\n",
    "ann_model_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/ANN/train-1/ann_weights_train_1.tar\"\n",
    "\n",
    "state_dict_lr = torch.load(lr_model_path)\n",
    "state_dict_ann = torch.load(ann_model_path)\n",
    "\n",
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Couldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ANN(nn.Module):\n",
    "\n",
    "#     def __init__(self, input_size):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         hidden_layer_num = int(input_size / 2)\n",
    "\n",
    "#         self.linear1 = nn.Linear(input_size, hidden_layer_num)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(hidden_layer_num, hidden_layer_num)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.linear3 = nn.Linear(hidden_layer_num + input_size, 1)\n",
    "#         self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         h = self.linear1(x)\n",
    "#         h = self.relu1(h)\n",
    "#         h = self.linear2(h)\n",
    "#         h = self.relu2(h)\n",
    "#         h = torch.cat((x, h), dim=1)\n",
    "#         h = self.linear3(h)\n",
    "        \n",
    "#         return self.sig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_layer_num = int(input_size / 2)\n",
    "\n",
    "        self.linear1 = nn.Linear(input_size, hidden_layer_num)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_layer_num + input_size, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.linear1(x)\n",
    "        h = self.relu1(h)\n",
    "        h = torch.cat((x, h), dim=1)\n",
    "        h = self.linear2(h)\n",
    "        \n",
    "        return self.sig(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegresion(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return self.sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SharkDataset()\n",
    "\n",
    "test_data_loader = data.DataLoader(test_dataset, batch_size=500_000, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegresion(\n",
       "  (linear): Linear(in_features=85, out_features=1, bias=True)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_state = torch.load(\"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/ANN/train-4/ann_weights_train_4.tar\")\n",
    "lr_state = torch.load(\"/home/meribejayson/Desktop/Projects/SharkCNN/training_models/LOGISTIC-REG/train-final-6/lr_weights_train_6.tar\")\n",
    "\n",
    "ann_model = ANN(85)\n",
    "ann_model.load_state_dict(ann_state)\n",
    "ann_model.to(device)\n",
    "\n",
    "\n",
    "lr_model = LogisticRegresion(85)\n",
    "lr_model.load_state_dict(lr_state)\n",
    "lr_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(preds, data_labels):\n",
    "    conf_thresholds = [0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] \n",
    "    precision_varying = []\n",
    "    recall_varying = []\n",
    "    f1_score_varying = []\n",
    "\n",
    "    for thresh in conf_thresholds:\n",
    "        TP = preds[(preds > thresh) & (data_labels == 1.0)].size(dim=0)\n",
    "        FP = preds[(preds > thresh) & (data_labels == 0.0)].size(dim=0)\n",
    "        FN = preds[(preds < thresh) & (data_labels == 1.0)].size(dim=0)\n",
    "\n",
    "        if(TP + FN + FP == 0):\n",
    "            return None\n",
    "\n",
    "        curr_thresh_precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "        curr_thresh_recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "\n",
    "        curr_thresh_f1_score = (2 * curr_thresh_precision * curr_thresh_recall) / (curr_thresh_recall + curr_thresh_precision) if (curr_thresh_recall + curr_thresh_precision) != 0 else 0\n",
    "\n",
    "\n",
    "        precision_varying.append(curr_thresh_precision)\n",
    "        recall_varying.append(curr_thresh_recall)\n",
    "        f1_score_varying.append(curr_thresh_f1_score)\n",
    "\n",
    "    MAP_50 = precision_varying[0]\n",
    "    MAP50_95 = np.mean(np.array(precision_varying))\n",
    "\n",
    "    best_f1_score_idx = np.argmax(np.array(curr_thresh_f1_score))\n",
    "    \n",
    "    f1_score = f1_score_varying[best_f1_score_idx]\n",
    "    recall = recall_varying[best_f1_score_idx]\n",
    "    precision = precision_varying[best_f1_score_idx]\n",
    "\n",
    "    return {\n",
    "        \"MAP50\": MAP_50,\n",
    "        \"MAP50_95\": MAP50_95,\n",
    "        \"F1_Score\": f1_score,\n",
    "        \"Recall\": recall,\n",
    "        \"Precision\": precision\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(data_loader):\n",
    "    ann_model.eval()\n",
    "    lr_model.eval()\n",
    "\n",
    "    curr_iter = 1\n",
    "    \n",
    "    # Logisitic Regression Stats\n",
    "    precision_lr = np.array([])\n",
    "    recall_lr = np.array([])\n",
    "    pr_thresh_lr = np.array([]) \n",
    "\n",
    "    tpr_lr = np.array([])\n",
    "    fpr_lr = np.array([])\n",
    "    tp_thresh_lr = np.array([])\n",
    "\n",
    "    f1_score_lr = np.array([])\n",
    "    f1_thresh_lr = np.array([])\n",
    "\n",
    "    map_50_lr = np.array([])\n",
    "    map_50_95_lr = np.array([])\n",
    "\n",
    "    # ANN Stats \n",
    "    precision_ann = np.array([])\n",
    "    recall_ann = np.array([])\n",
    "    pr_thresh_ann = np.array([]) \n",
    "\n",
    "    tpr_ann = np.array([])\n",
    "    fpr_ann = np.array([])\n",
    "    tp_thresh_ann = np.array([])\n",
    "\n",
    "    f1_score_ann = np.array([])\n",
    "    f1_thresh_ann = np.array([])\n",
    "\n",
    "    map_50_ann = np.array([])\n",
    "    map_50_95_ann = np.array([])\n",
    "    \n",
    "    confs = [0.5, 0.55, 0.60, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]\n",
    "    \n",
    "    # Beware inefficient code lays ahead\n",
    "    while(curr_iter < 300):\n",
    "        with torch.no_grad():\n",
    "            for point in data_loader:\n",
    "                data_inputs = point[:, :-1].to(device).float()\n",
    "                data_labels = point[:, -1].to(device).float()\n",
    "\n",
    "                labels = data_labels.to('cpu').numpy().astype(int).flatten()\n",
    "                \n",
    "                ann_preds = ann_model(data_inputs).to('cpu').numpy().flatten()\n",
    "                lr_preds = lr_model(data_inputs).to('cpu').numpy().flatten()\n",
    "\n",
    "                # Precision Recall\n",
    "                curr_precision_ann, curr_recall_ann, curr_pr_thresh_ann = precision_recall_curve(labels, ann_preds)\n",
    "                curr_precision_lr, curr_recall_lr, curr_pr_thresh_lr = precision_recall_curve(labels, lr_preds)\n",
    "\n",
    "                precision_ann = np.append(precision_ann, curr_precision_ann)\n",
    "                precision_lr = np.append(precision_lr, curr_precision_lr)\n",
    "\n",
    "                recall_ann = np.append(recall_ann, curr_recall_ann)\n",
    "                recall_lr = np.append(recall_lr, curr_recall_lr)\n",
    "\n",
    "                pr_thresh_ann = np.concatenate((pr_thresh_ann, curr_pr_thresh_ann, np.array([1])))\n",
    "                pr_thresh_lr = np.concatenate((pr_thresh_lr, curr_pr_thresh_lr, np.array([1])))\n",
    "\n",
    "                # ROC\n",
    "                curr_fpr_ann, curr_tpr_ann, curr_tp_thresh_ann = roc_curve(labels, ann_preds)\n",
    "                curr_fpr_lr, curr_tpr_lr, curr_tp_thresh_lr = roc_curve(labels, lr_preds)\n",
    "\n",
    "                fpr_ann = np.append(fpr_ann, curr_fpr_ann)\n",
    "                tpr_ann = np.append(tpr_ann, curr_tpr_ann)\n",
    "                tp_thresh_ann = np.append(tp_thresh_ann, curr_tp_thresh_ann)\n",
    "\n",
    "                fpr_lr = np.append(fpr_lr, curr_fpr_lr)\n",
    "                tpr_lr = np.append(tpr_lr, curr_tpr_lr)\n",
    "                tp_thresh_lr = np.append(tp_thresh_lr, curr_tp_thresh_lr)\n",
    "\n",
    "                # F1 Score\n",
    "                f1_score_lr = np.append(f1_score_lr, (2 * precision_lr * recall_lr) / (precision_lr + recall_lr))\n",
    "                f1_thresh_lr = np.append(f1_thresh_lr, pr_thresh_lr)\n",
    "\n",
    "                f1_score_ann = np.append(f1_score_ann, (2 * precision_ann * recall_ann) / (precision_ann + recall_ann))\n",
    "                f1_thresh_ann = np.append(f1_thresh_ann, pr_thresh_ann)\n",
    "\n",
    "                f1_score_lr[np.isnan(f1_score_lr)] = 0\n",
    "                f1_score_ann[np.isnan(f1_score_ann)] = 0\n",
    "\n",
    "                # MAP 50\n",
    "                map_50_lr = np.append(map_50_lr, np.mean(precision_lr[pr_thresh_lr > 0.5]))\n",
    "                map_50_ann = np.append(map_50_ann, np.mean(precision_ann[pr_thresh_ann > 0.5]))\n",
    "\n",
    "                # MAP 50-95\n",
    "                map_temp_lr = 0\n",
    "\n",
    "                for conf in confs:\n",
    "                    map_temp_lr += np.mean(precision_lr[pr_thresh_lr > conf])\n",
    "\n",
    "\n",
    "                map_50_95_lr = np.append(map_50_lr, np.mean(map_temp_lr))\n",
    "\n",
    "\n",
    "                map_temp_ann = 0\n",
    "\n",
    "                for conf in confs:\n",
    "                    map_temp_ann += np.mean(precision_ann[pr_thresh_ann > conf])\n",
    "\n",
    "\n",
    "                map_50_95_ann = np.append(map_50_ann, map_temp_ann)\n",
    "\n",
    "\n",
    "                MAP_50_ANN = np.mean(map_50_ann)\n",
    "                MAP_50_95_ANN = np.mean(map_50_95_ann)\n",
    "                f1_score_ANN = np.mean(f1_score_ann)\n",
    "                recall_ANN = np.mean(recall_ann)\n",
    "                precision_ANN = np.mean(precision_ann)\n",
    "\n",
    "                MAP_50_LR = np.mean(map_50_lr)\n",
    "                MAP_50_95_LR = np.mean(map_50_95_lr)\n",
    "                f1_score_LR = np.mean(f1_score_lr)\n",
    "                recall_LR = np.mean(recall_lr)\n",
    "                precision_LR = np.mean(precision_lr)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "                print(f'Current iteration: {curr_iter}')\n",
    "                print('='*60)\n",
    "                print(\"ANN Metrics\")\n",
    "                print(f\"MAP50: {MAP_50_ANN} MAP50-95: {MAP_50_95_ANN} Precision: {precision_ANN} Recall: {recall_ANN} F1 score: {f1_score_ANN}\")\n",
    "                print(\"\\n\")\n",
    "                print(\"LR Metrics\")\n",
    "                print(f\"MAP50: {MAP_50_LR} MAP50-95: {MAP_50_95_LR} Precision: {precision_LR} Recall: {recall_LR} F1 score: {f1_score_LR}\")\n",
    "                print('='*60)\n",
    "                print(f\"CPU Usage: {psutil.cpu_percent()}% GPU memory usage: {int(info.used / info.total)}% \\n\")\n",
    "\n",
    "            roc_sorted_ann_idx = np.argsort(tp_thresh_ann)[::-1]\n",
    "            roc_sorted_lr_idx = np.argsort(tp_thresh_lr)[::-1]\n",
    "\n",
    "            roc_plot_ann = RocCurveDisplay(fpr=fpr_ann[roc_sorted_ann_idx], tpr=tpr_ann[roc_sorted_ann_idx])\n",
    "            roc_plot_ann.plot()\n",
    "            plt.title('ROC ANN')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "\n",
    "            roc_plot_lr = RocCurveDisplay(fpr=fpr_lr[roc_sorted_lr_idx], tpr=tpr_lr[roc_sorted_lr_idx])\n",
    "            roc_plot_lr.plot()\n",
    "            plt.title('ROC LR')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "            pr_sorted_ann_idx = np.argsort(recall_ann)[::-1]\n",
    "            pr_sorted_lr_idx = np.argsort(recall_lr)[::-1]\n",
    "\n",
    "            pr_plot_ann = PrecisionRecallDisplay(precision=precision_ann[pr_sorted_ann_idx][precision_ann[pr_sorted_ann_idx] < 1], recall=recall_ann[pr_sorted_ann_idx][precision_ann[pr_sorted_ann_idx] < 1])\n",
    "            pr_plot_ann.plot()\n",
    "            plt.title('Precision-Recall ANN')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "            pr_plot_lr = PrecisionRecallDisplay(precision=precision_lr[pr_sorted_lr_idx], recall=recall_lr[pr_sorted_lr_idx])\n",
    "            pr_plot_lr.plot()\n",
    "            plt.title('Precision-Recall LR')\n",
    "            plt.show()\n",
    "            plt.clf()\n",
    "\n",
    "\n",
    "            f1_sorted_ann_idx = np.argsort(f1_thresh_ann)\n",
    "            f1_sorted_lr_idx = np.argsort(f1_thresh_lr)\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(f1_thresh_ann[f1_sorted_ann_idx], f1_score_ann[f1_sorted_ann_idx], color='blue')\n",
    "\n",
    "            plt.xlabel('Confidence')\n",
    "            plt.ylabel('F1-Score')\n",
    "            plt.title('F1-Score ANN')\n",
    "            plt.show()\n",
    "            \n",
    "            plt.clf()\n",
    "\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.plot(f1_thresh_lr[f1_sorted_lr_idx], f1_score_lr[f1_sorted_lr_idx], color='blue')\n",
    "\n",
    "\n",
    "            plt.xlabel('Confidence')\n",
    "            plt.ylabel('F1-Score')\n",
    "            plt.title('F1-Score LR')\n",
    "            plt.show()\n",
    "\n",
    "            plt.clf()\n",
    "\n",
    "        curr_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current iteration: 1\n",
      "============================================================\n",
      "ANN Metrics\n",
      "MAP50: 0.016835039197036192 MAP50-95: 0.019763981039392937 Precision: 0.012668502531838956 Recall: 0.515118300997106 F1 score: 0.02380620901774135\n",
      "\n",
      "\n",
      "LR Metrics\n",
      "MAP50: 0.00402943334309197 MAP50-95: 0.004429600194712127 Precision: 0.006315623392305757 Recall: 0.3565918138341444 F1 score: 0.01225374945561506\n",
      "============================================================\n",
      "CPU Usage: 5.7% GPU memory usage: 0% \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_142511/751797412.py:77: RuntimeWarning: invalid value encountered in divide\n",
      "  f1_score_lr = np.append(f1_score_lr, (2 * precision_lr * recall_lr) / (precision_lr + recall_lr))\n"
     ]
    }
   ],
   "source": [
    "eval_model(test_data_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
