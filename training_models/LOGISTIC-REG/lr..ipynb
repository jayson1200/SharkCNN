{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"COuldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "megaset_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/\"\n",
    "megaset_train_images_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/images/\"\n",
    "megaset_train_labels_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/labels/\"\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegresion(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return self.sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharkDataset(data.IterableDataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SharkDataset).__init__()\n",
    "        self.image_names = os.listdir(megaset_train_images_path)\n",
    "        self.num_images = len(self.image_names)\n",
    "        self.curr_image_ordering = np.arange(self.num_images, dtype=np.int32)\n",
    "        self.curr_image_idx = 0\n",
    "\n",
    "        self.reset_random_image_ord()\n",
    "\n",
    "        self.transform = A.Compose(\n",
    "            [\n",
    "               A.Blur(p=0.01, blur_limit=(3,7)),\n",
    "               A.MedianBlur(p=0.01, blur_limit=(3,7)),\n",
    "               A.ToGray(p=0.01),\n",
    "               A.CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def reset_random_image_ord(self):\n",
    "        self.curr_image_order = np.random.shuffle(self.curr_image_ordering)\n",
    "        self.curr_image_idx = 0\n",
    "\n",
    "    \"\"\"\n",
    "        The following return a numpy array representing the image in BGR format\n",
    "    \"\"\"\n",
    "    def get_random_image(self):\n",
    "        if(self.curr_image_idx == self.num_images):\n",
    "            self.reset_random_image_order()\n",
    "\n",
    "        image_name = self.image_names[self.curr_image_ordering[self.curr_image_idx]]\n",
    "        file_path = megaset_train_images_path + image_name\n",
    "        image = cv2.imread(file_path)\n",
    "\n",
    "        self.curr_image_idx += 1\n",
    "\n",
    "        return (image_name, image)\n",
    "\n",
    "    def transform_image(self, image):\n",
    "        return self.transform(image=image)[\"image\"]\n",
    "    \n",
    "    \"\"\"\n",
    "        Assumes input image is in grayscale\n",
    "    \"\"\"\n",
    "    def get_canny_output(self, image):\n",
    "        return cv2.Canny(image, 50, 100)\n",
    "    \n",
    "    \"\"\"\n",
    "        Expecting image in BGR format\n",
    "    \"\"\"\n",
    "    def get_color_gradients(self, image):\n",
    "        blue_dy = ski.filters.sobel_h(image[:, :, 0])\n",
    "        blue_dx = ski.filters.sobel_v(image[:, :, 0])\n",
    "\n",
    "        green_dy = ski.filters.sobel_h(image[:, :, 1])\n",
    "        green_dx = ski.filters.sobel_v(image[:, :, 1])\n",
    "\n",
    "        red_dy = ski.filters.sobel_h(image[:, :, 2])\n",
    "        red_dx = ski.filters.sobel_v(image[:, :, 2])\n",
    "\n",
    "        return (blue_dx, blue_dy, green_dx, green_dy, red_dx, red_dy)\n",
    "    \n",
    "    def get_direction(self, image_dx, image_dy):\n",
    "        peturbation = 1e-5\n",
    "\n",
    "        image_dy_peturb = copy.deepcopy(image_dy)\n",
    "        image_dx_peturb = copy.deepcopy(image_dx)\n",
    "\n",
    "        image_dy_peturb[image_dy == 0.0] = peturbation\n",
    "        image_dx_peturb[image_dx == 0.0] = peturbation\n",
    "\n",
    "        return np.arctan(image_dy_peturb / image_dx_peturb)\n",
    "\n",
    "    \"\"\"\n",
    "        Expecting image in BGR format\n",
    "\n",
    "        return gabor feature image per channel (8, 1080, 1920)\n",
    "    \"\"\"\n",
    "    def get_gabor_feature_vector(self, image):\n",
    "        size = 20\n",
    "        pi_2 = np.pi / 2\n",
    "\n",
    "        sigma = np.array([1.0, 1.0, 3.0, 1.0, 3.0, 1.0, 2.0, 1.0])\n",
    "        theta = np.array([0.0, 0.0, 0.2617993877991494, 0.5235987755982988, 0.2617993877991494, 0.2617993877991494, 0.0, 0.0])\n",
    "        lambd = np.array([10.0, 15.0, 20.0, 15.0, 20.0, 20.0, 15.0, 20.0])\n",
    "        gamma = np.array([0.5, 1.5, 1.5, 1.5, 1.0, 1.5, 1.5, 1.0])\n",
    "        psi = np.array([pi_2, pi_2, pi_2, pi_2, pi_2, pi_2, pi_2, pi_2])\n",
    "\n",
    "        R = []\n",
    "        G = []\n",
    "        B = []\n",
    "\n",
    "        for idx in range(sigma.shape[0]): \n",
    "            kern = cv2.getGaborKernel((size, size), sigma[idx], theta[idx], lambd[idx], gamma[idx], psi[idx], ktype=cv2.CV_64F)\n",
    "            B.append(cv2.filter2D(image[:, :, 0], -1, kern))\n",
    "            G.append(cv2.filter2D(image[:, :, 1], -1, kern))\n",
    "            R.append(cv2.filter2D(image[:, :, 2], -1, kern))\n",
    "            \n",
    "        \n",
    "        R_np = np.array(R)\n",
    "        G_np = np.array(G)\n",
    "        B_np = np.array(B)\n",
    "         \n",
    "        return (B_np, G_np, R_np)\n",
    "    \n",
    "    def get_gabor_feature_gradients(self, B_np, G_np, R_np):\n",
    "        R_dx = []\n",
    "        G_dx = []\n",
    "        B_dx = []\n",
    "\n",
    "        R_dy = []\n",
    "        G_dy = []\n",
    "        B_dy = []\n",
    "\n",
    "        for i in range(B_np.shape[0]):\n",
    "            B_dx.append(ski.filters.sobel_v(B_np[i, :, :]))\n",
    "            B_dy.append(ski.filters.sobel_h(B_np[i, :, :]))\n",
    "\n",
    "            G_dx.append(ski.filters.sobel_v(G_np[i, :, :]))\n",
    "            G_dy.append(ski.filters.sobel_h(G_np[i, :, :]))\n",
    "\n",
    "            R_dx.append(ski.filters.sobel_v(R_np[i, :, :]))\n",
    "            R_dy.append(ski.filters.sobel_h(R_np[i, :, :]))\n",
    "        \n",
    "        R_dx_np = np.array(R_dx)\n",
    "        R_dy_np = np.array(R_dy)\n",
    "\n",
    "        G_dx_np = np.array(G_dx)\n",
    "        G_dy_np = np.array(G_dy)\n",
    "\n",
    "        B_dx_np = np.array(B_dx)\n",
    "        B_dy_np = np.array(B_dy)\n",
    "\n",
    "        return (B_dx_np, B_dy_np, G_dx_np, G_dy_np, R_dx_np, R_dy_np) \n",
    "\n",
    "    def is_pixel_in_box(self, image_name, pixel_loc_x, pixel_loc_y):\n",
    "        label_name = image_name.split(\".\")[0] + \".txt\"\n",
    "        label_path = megaset_train_labels_path + label_name\n",
    "\n",
    "        labels = []\n",
    "        \n",
    "        with open(label_path, \"r\") as labels_doc:\n",
    "            labels = labels_doc.read().splitlines()\n",
    "\n",
    "        \n",
    "        for labels_string in labels:\n",
    "            box_keypoints = [float(keypoint_string) for keypoint_string in labels_string.split(\" \")]\n",
    "            points = np.array([[box_keypoints[1], box_keypoints[2]], \n",
    "                               [box_keypoints[3], box_keypoints[4]], \n",
    "                               [box_keypoints[5], box_keypoints[6]], \n",
    "                               [box_keypoints[7], box_keypoints[8]]], dtype=np.float32)\n",
    "            \n",
    "            pixel_norm_loc = np.array([pixel_loc_x / image_width, pixel_loc_y / image_height])\n",
    "\n",
    "            if(cv2.pointPolygonTest(points,  pixel_norm_loc, False) >= 0):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "    \n",
    "\n",
    "\n",
    "    def test_shark_dataset_functions(self):\n",
    "        # Test get_random_image\n",
    "        image_name, image = self.get_random_image()\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        # Test transform_image\n",
    "        transformed_image = self.transform_image(image)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Transformed Image\")\n",
    "        plt.imshow(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        \n",
    "        # Test get_canny_output (Assuming the transformed image is suitable)\n",
    "        canny_output = self.get_canny_output(cv2.cvtColor(transformed_image, cv2.COLOR_RGB2GRAY))\n",
    "        plt.figure()\n",
    "        plt.title(\"Canny Output\")\n",
    "        plt.imshow(canny_output, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # Test get_color_gradients\n",
    "        blue_dx, blue_dy, green_dx, green_dy, red_dx, red_dy = self.get_color_gradients(image)\n",
    "        # Visualizing one of the gradients\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(\"Gradient - Blue Channel DX\")\n",
    "        plt.imshow(blue_dx, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # No direct visualization for get_direction as it's more of a computation method\n",
    "        \n",
    "        # Test get_gabor_feature_vector\n",
    "        B_np, G_np, R_np = self.get_gabor_feature_vector(image)\n",
    "        # Visualize one of the Gabor feature images\n",
    "        plt.figure()\n",
    "        plt.title(\"Gabor Feature - Blue Channel\")\n",
    "        plt.imshow(B_np[0], cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        # Test get_gabor_feature_gradients (Using Gabor features from previous step)\n",
    "        B_dx_np, B_dy_np, G_dx_np, G_dy_np, R_dx_np, R_dy_np = self.get_gabor_feature_gradients(B_np, G_np, R_np)\n",
    "        # Visualize one of the gradient images\n",
    "        plt.figure()\n",
    "        plt.title(\"Gabor Feature Gradient - Blue Channel DX\")\n",
    "        plt.imshow(B_dx_np[0], cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "        # Testing is_pixel_in_box function\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        overlay = image.copy()\n",
    "        \n",
    "        # Iterate over each pixel in the image\n",
    "        for y in range(image.shape[0]):\n",
    "            for x in range(image.shape[1]):\n",
    "                if self.is_pixel_in_box(image_name, x, y):\n",
    "                    overlay[y, x] = [255, 0, 0]  # Red for inside box\n",
    "\n",
    "        # Blend the original image with the overlay\n",
    "        alpha = 0.25  # Transparency factor\n",
    "        output_image = cv2.addWeighted(image_rgb, 1 - alpha, cv2.cvtColor(overlay, cv2.COLOR_BGR2RGB), alpha, 0)\n",
    "\n",
    "        # Display the original and the output image\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image_rgb)\n",
    "        plt.title('Original Image')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(output_image)\n",
    "        plt.title('Overlay Image')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # I  standardize each image because each image has a different feature distribution, which will make it hard for our model to learn weights that generalize across all images\n",
    "    def standardize(self, mat):\n",
    "        return(mat - np.mean(mat)) / np.std(mat)\n",
    "    \n",
    "    def generate_image_features(self):\n",
    "        image_name, image = self.get_random_image()\n",
    "\n",
    "        image = self.transform_image(image)\n",
    "\n",
    "        # Canny\n",
    "        image_canny_stand = self.standardize(self.get_canny_output(image))\n",
    "\n",
    "        # Color Gradient\n",
    "        blue_dx, blue_dy, green_dx, green_dy, red_dx, red_dy = self.get_color_gradients(image)\n",
    "        \n",
    "        blue_dx_stand = self.standardize(blue_dx)\n",
    "        blue_dy_stand = self.standardize(blue_dy)\n",
    "        green_dx_stand = self.standardize(green_dx)\n",
    "        green_dy_stand = self.standardize(green_dy)\n",
    "        red_dx_stand = self.standardize(red_dx)\n",
    "        red_dy_stand =  self.standardize(red_dy)\n",
    "\n",
    "        # Gradient Direction\n",
    "        blue_direction = self.get_direction(blue_dx, blue_dy)\n",
    "        green_direction = self.get_direction(green_dx, green_dy)\n",
    "        red_direction = self.get_direction(red_dx, red_dy)\n",
    "\n",
    "\n",
    "        # Texture Feature Vectors and Gradients\n",
    "        blue_text_stand, green_text_stand, red_text_stand = self.get_gabor_feature_vector(image)\n",
    "\n",
    "        blue_text_dx_stand, blue_text_dy_stand, green_text_dx_stand, green_text_dy_stand, red_text_dx_stand, red_text_dy_stand = self.get_gabor_feature_gradients(blue_text_stand, green_text_stand, red_text_stand)\n",
    "\n",
    "        for i in range(blue_text_stand.shape[0]):\n",
    "            blue_text_stand[i, :, :] = self.standardize(blue_text_stand[i, :, :])\n",
    "            green_text_stand[i, :, :] = self.standardize(green_text_stand[i, :, :])\n",
    "            red_text_stand[i, :, :] = self.standardize(red_text_stand[i, :, :])\n",
    "\n",
    "        for i in range(blue_text_dx_stand.shape[0]):\n",
    "            blue_text_dx_stand[i, :, :] = self.standardize(blue_text_dx_stand[i, :, :])\n",
    "            blue_text_dy_stand[i, :, :] = self.standardize(blue_text_dy_stand[i, :, :])\n",
    "\n",
    "            green_text_dx_stand[i, :, :] = self.standardize(green_text_dx_stand[i, :, :])\n",
    "            green_text_dy_stand[i, :, :] = self.standardize(green_text_dy_stand[i, :, :])\n",
    "\n",
    "            red_text_dx_stand[i, :, :] = self.standardize(red_text_dx_stand[i, :, :])\n",
    "            red_text_dy_stand[i, :, :] = self.standardize(red_text_dy_stand[i, :, :])\n",
    "\n",
    "        image_per_pixel_feats = np.empty((image_height * image_width, 86))\n",
    "        \n",
    "        # Color\n",
    "        blue_stand = self.standardize(image[:, :, 0])\n",
    "        green_stand = self.standardize(image[:, :, 1])\n",
    "        red_stand = self.standardize(image[:, :, 2])\n",
    "\n",
    "        # Creating features\n",
    "\n",
    "        curr_idx = 0\n",
    "\n",
    "        for y in range(image_height):\n",
    "            for x in range(image_width):\n",
    "                curr_y = 1 if self.is_pixel_in_box(image_name, x, y) else 0 \n",
    "\n",
    "                pixel_features = np.array([red_stand[y, x], green_stand[y, x], blue_stand[y, x], \n",
    "                                           image_canny_stand[y, x], \n",
    "                                           red_dx_stand[y, x], red_dy_stand[y, x], green_dx_stand[y, x], green_dy_stand[y, x], blue_dx_stand[y, x], blue_dy_stand[y, x], \n",
    "                                           red_direction[y, x], green_direction[y, x], blue_direction[y, x], \n",
    "                                           red_text_stand[0, y, x], red_text_stand[1, y, x], red_text_stand[2, y, x], red_text_stand[3, y, x], red_text_stand[4, y, x], red_text_stand[5, y, x], red_text_stand[6, y, x], red_text_stand[7, y, x],\n",
    "                                           blue_text_stand[0, y, x], blue_text_stand[1, y, x], blue_text_stand[2, y, x], blue_text_stand[3, y, x], blue_text_stand[4, y, x], blue_text_stand[5, y, x], blue_text_stand[6, y, x], blue_text_stand[7, y, x],\n",
    "                                           green_text_stand[0, y, x], green_text_stand[1, y, x], green_text_stand[2, y, x], green_text_stand[3, y, x], green_text_stand[4, y, x], green_text_stand[5, y, x], green_text_stand[6, y, x], green_text_stand[7, y, x],\n",
    "                                           red_text_dx_stand[0, y, x], red_text_dx_stand[1, y, x], red_text_dx_stand[2, y, x], red_text_dx_stand[3, y, x], red_text_dx_stand[4, y, x], red_text_dx_stand[5, y, x], red_text_dx_stand[6, y, x], red_text_dx_stand[7, y, x],\n",
    "                                           blue_text_dx_stand[0, y, x], blue_text_dx_stand[1, y, x], blue_text_dx_stand[2, y, x], blue_text_dx_stand[3, y, x], blue_text_dx_stand[4, y, x], blue_text_dx_stand[5, y, x], blue_text_dx_stand[6, y, x], blue_text_dx_stand[7, y, x],\n",
    "                                           green_text_dx_stand[0, y, x], green_text_dx_stand[1, y, x], green_text_dx_stand[2, y, x], green_text_dx_stand[3, y, x], green_text_dx_stand[4, y, x], green_text_dx_stand[5, y, x], green_text_dx_stand[6, y, x], green_text_dx_stand[7, y, x],\n",
    "                                           red_text_dy_stand[0, y, x], red_text_dy_stand[1, y, x], red_text_dy_stand[2, y, x], red_text_dy_stand[3, y, x], red_text_dy_stand[4, y, x], red_text_dy_stand[5, y, x], red_text_dy_stand[6, y, x], red_text_dy_stand[7, y, x],\n",
    "                                           blue_text_dy_stand[0, y, x], blue_text_dy_stand[1, y, x], blue_text_dy_stand[2, y, x], blue_text_dy_stand[3, y, x], blue_text_dy_stand[4, y, x], blue_text_dy_stand[5, y, x], blue_text_dy_stand[6, y, x], blue_text_dy_stand[7, y, x],\n",
    "                                           green_text_dy_stand[0, y, x], green_text_dy_stand[1, y, x], green_text_dy_stand[2, y, x], green_text_dy_stand[3, y, x], green_text_dy_stand[4, y, x], green_text_dy_stand[5, y, x], green_text_dy_stand[6, y, x], green_text_dy_stand[7, y, x],\n",
    "                                           curr_y])\n",
    "                \n",
    "                image_per_pixel_feats[curr_idx, :] = pixel_features\n",
    "\n",
    "                curr_idx += 1\n",
    "        \n",
    "        return image_per_pixel_feats\n",
    "\n",
    "    def __iter__(self):\n",
    "        data = np.empty((image_height * image_width * 2, 86))\n",
    "        data[:(image_height * image_width), :] = self.generate_image_features()\n",
    "        data[(image_height * image_width):(image_height * image_width * 2), :] = self.generate_image_features()\n",
    "\n",
    "        return iter(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_dataset = SharkDataset()\n",
    "data_loader = data.DataLoader(shark_dataset, batch_size=10, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegresion(85)\n",
    "model.to(device)\n",
    "\n",
    "loss_mod = nn.BCEWithLogitsLoss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for point in data_loader:\n",
    "    print(point) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        for point in data_loader:\n",
    "            ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "            data_inputs = point[:-1].to(device)\n",
    "            data_labels = point[-1].to(device)\n",
    "\n",
    "            ## Step 2: Run the model on the input data\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# train_model(model, optimizer, data_loader, loss_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
