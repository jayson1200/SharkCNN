{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage as ski\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import psutil\n",
    "import pynvml\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/meribejayson/Desktop/Projects/SharkCNN/training_models/dataloaders/')\n",
    "\n",
    "from train_dataset import SharkDatasetTrain as SharkDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception(\"Couldn't find CUDA\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "pynvml.nvmlInit()\n",
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "\n",
    "megaset_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/\"\n",
    "megaset_train_images_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/images/\"\n",
    "megaset_train_labels_path = \"/home/meribejayson/Desktop/Projects/SharkCNN/datasets-reduced/megaset/train/labels/\"\n",
    "\n",
    "image_width = 1920\n",
    "image_height = 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegresion(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_size,1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return self.sig(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "shark_dataset = SharkDataset()\n",
    "data_loader = data.DataLoader(shark_dataset, batch_size=1_000_000, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load(\"./train-final-2/lr_weights_train_2.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegresion(85)\n",
    "# model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_NUM = 2e120\n",
    "target_loss_change = 1e-6\n",
    "exps_in_iter = (image_height * image_width * 2)\n",
    "kappa = 1 / 323\n",
    "kappa_inv = 323\n",
    "coef = (1 + kappa) / 2\n",
    "\n",
    "def train_model(model, optimizer, data_loader):\n",
    "    model.train()\n",
    "    last_average_loss = LARGE_NUM\n",
    "    curr_average_loss = 0\n",
    "    curr_iter = 1\n",
    "\n",
    "    while(np.abs(curr_average_loss - last_average_loss) > target_loss_change):\n",
    "        \n",
    "        total_iter_avg_loss = 0\n",
    "        total_points = 0\n",
    "\n",
    "        for point in data_loader:\n",
    "            data_inputs = point[:, :-1].to(device).float()\n",
    "            data_labels = point[:, -1].to(device).float()\n",
    "\n",
    "            preds = model(data_inputs).squeeze(dim=1)\n",
    "\n",
    "            weights = torch.ones_like(data_labels)\n",
    "            weights[data_labels == 1.0] = kappa_inv\n",
    "            weights *= coef\n",
    "            \n",
    "            loss_module = nn.BCELoss(weight=weights)\n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_iter_avg_loss += loss.item() * data_inputs.size(0)\n",
    "            total_points += data_inputs.size(0)\n",
    " \n",
    "        last_average_loss = curr_average_loss\n",
    "        curr_average_loss = total_iter_avg_loss / total_points\n",
    "        \n",
    "        info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        clear_output(wait=True)\n",
    "        print(f'Current iteration: {curr_iter - 1}, Average Loss: {last_average_loss}')\n",
    "        print(f'Current iteration: {curr_iter}, Average Loss: {curr_average_loss}')\n",
    "        print(f\"CPU Usage: {psutil.cpu_percent()}% GPU memory usage: {int(info.used / info.total)}% \\n\")\n",
    "\n",
    "        print(\"Current Parameters:\")\n",
    "        for name, param in model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "\n",
    "        curr_iter += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, optimizer, data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[ 8.8438e-02, -4.1447e-02,  5.7988e-02,  2.5508e-01,  2.1914e-01,\n",
      "          4.1002e-02,  1.2102e-01,  2.4286e-02,  2.7373e-01,  5.5927e-02,\n",
      "          1.5209e-02, -7.9003e-02, -1.0960e-02, -1.7376e-01, -2.4090e-01,\n",
      "         -1.8512e-01, -2.1791e-01, -2.7587e-01, -1.2228e-01, -1.0727e-01,\n",
      "         -1.2169e-01, -1.4348e-01, -1.3062e-01, -1.9141e-01, -2.1120e-01,\n",
      "         -2.9247e-01, -1.2279e-01, -1.0668e-01, -1.2639e-01, -1.8587e-01,\n",
      "         -2.6121e-01, -1.7965e-01, -2.2002e-01, -2.6013e-01, -1.2802e-01,\n",
      "         -1.1201e-01, -1.4598e-01,  1.7382e-03,  3.8620e-03, -4.4278e-03,\n",
      "          1.7996e-02, -1.1002e-02,  2.4375e-03,  5.7739e-03, -1.1377e-03,\n",
      "          8.4366e-03,  8.9391e-03,  3.1053e-02,  2.5116e-02,  2.1628e-02,\n",
      "          8.6249e-03,  2.6799e-02,  4.3937e-03, -3.9218e-03, -9.3392e-04,\n",
      "         -3.5854e-02,  1.2282e-02, -4.6147e-02, -1.9868e-03, -1.0342e-02,\n",
      "         -6.3967e-03,  4.6510e-03,  1.6078e-03, -1.2351e-03, -5.8392e-03,\n",
      "          2.4910e-03, -2.2267e-03,  8.2041e-03, -3.0381e-03,  7.0405e-03,\n",
      "          2.2529e-03,  1.3210e-05, -1.4595e-03,  2.0554e-03,  3.4146e-04,\n",
      "          1.1622e-02, -1.9817e-03,  1.7390e-03,  1.5808e-03, -9.3156e-03,\n",
      "         -9.1757e-03, -6.4467e-03, -4.3617e-03,  2.7918e-03, -3.7956e-03]],\n",
      "       device='cuda:0')), ('linear.bias', tensor([-6.0242], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "pynvml.nvmlShutdown()\n",
    "state_dict = model.state_dict()\n",
    "print(state_dict)\n",
    "torch.save(state_dict, \"lr_weights_train_4.tar\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
